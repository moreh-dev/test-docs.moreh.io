"use strict";(self.webpackChunkmif_docs=self.webpackChunkmif_docs||[]).push([[1650],{8679(e,n,r){r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"features/prefill_decode_disaggregation","title":"Prefill-decode disaggregation","description":"During LLM inference, computation occurs in two stages: prefill and decode. In the prefill phase, the model processes the entire input prompt to generate the first token &mdash; a highly parallel, compute-bound process. The decode phase then predicts one token at a time, reusing the growing KV cache, and is memory-bound.","source":"@site/versioned_docs/version-v0.0.0/features/prefill_decode_disaggregation.md","sourceDirName":"features","slug":"/features/prefill_decode_disaggregation","permalink":"/features/prefill_decode_disaggregation","draft":false,"unlisted":false,"tags":[],"version":"v0.0.0","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Prefill-decode disaggregation"},"sidebar":"docs","previous":{"title":"Presets","permalink":"/features/preset"},"next":{"title":"Expert parallelism","permalink":"/features/expert_parallelism"}}');var t=r(4848),a=r(8453),s=r(9489),l=r(7227);const o={sidebar_position:2,title:"Prefill-decode disaggregation"},d="Prefill-decode disaggregation",c={},h=[{value:"Key features",id:"key-features",level:2},{value:"Manual configuration of PD disaggregation",id:"manual-configuration-of-pd-disaggregation",level:2},{value:"Example: PD disaggregation on Llama 3.3 70B",id:"example-pd-disaggregation-on-llama-33-70b",level:2},{value:"Benchmarking environment and configuration",id:"benchmarking-environment-and-configuration",level:3},{value:"Deployment",id:"deployment",level:3},{value:"Benchmarking",id:"benchmarking",level:3},{value:"Experimental results",id:"experimental-results",level:3}];function u(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"prefill-decode-disaggregation",children:"Prefill-decode disaggregation"})}),"\n",(0,t.jsx)(n.p,{children:"During LLM inference, computation occurs in two stages: prefill and decode. In the prefill phase, the model processes the entire input prompt to generate the first token \u2014 a highly parallel, compute-bound process. The decode phase then predicts one token at a time, reusing the growing KV cache, and is memory-bound."}),"\n",(0,t.jsx)(n.p,{children:"Because these phases have fundamentally different characteristics, prefill-decode (PD) disaggregation executes them on separate GPU resources. The prefill runs first on compute-optimized machines, then the KV cache is transferred to memory-optimized ones for decoding. This separation allows each phase to use its optimal parallelization, batch size, and configurations, while preventing interference between concurrent requests."}),"\n",(0,t.jsx)(n.p,{children:"PD disaggregation can improve key metrics such as time to first token (TTFT) and time per output token (TPOT) \u2014 since TTFT depends on prefill and TPOT on decode, dedicated optimization for each leads to better overall performance. However, because it also introduces communication overhead, which may negatively affect TTFT, PD disaggregation should be applied judiciously to ensure net efficiency gains."}),"\n",(0,t.jsx)(n.h2,{id:"key-features",children:"Key features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.strong,{children:"Heimdall"})," scheduler runs prefill-only and decode-only instances separately, allowing each to scale independently and managing request routing between them."]}),"\n",(0,t.jsx)(n.li,{children:"The framework can automatically determine whether to apply PD disaggregation and how to scale each phase according to defined service level objectives (SLOs)."}),"\n",(0,t.jsx)(n.li,{children:"Moreh vLLM is optimized to efficiently execute both prefill and decode phases of various models on AMD MI200 and MI300 series GPUs. It applies distinct parallelization and optimization strategies tailored to prefill-only and decode-only instances."}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"manual-configuration-of-pd-disaggregation",children:"Manual configuration of PD disaggregation"}),"\n",(0,t.jsxs)(n.p,{children:["To enable PD disaggregation, configure the prefill pod separately from the decode pod in the ",(0,t.jsx)(n.strong,{children:"Odin"})," inference service."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:"inference-service-values.yaml",children:"\n...\ndecode: ...\n\nprefill:\n  enabled: true\n\n  replicas: 4\n\n  resources:\n    requests:\n      amd.com/gpu: '2'\n    limits:\n      amd.com/gpu: '2'\n\n  extraArgs: ...\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Within the ",(0,t.jsx)(n.code,{children:"decode"})," and ",(0,t.jsx)(n.code,{children:"prefill"})," section, you can independently configure not only the number of replicas (",(0,t.jsx)(n.code,{children:"replicas"}),") but also the type and number of GPUs (",(0,t.jsx)(n.code,{children:"resources"}),") and the argument passed to the inference engine (",(0,t.jsx)(n.code,{children:"extraArgs"}),"). Make sure that the options specified in the ",(0,t.jsx)(n.code,{children:"extraArgs"})," field of the ",(0,t.jsx)(n.code,{children:"decode"})," or ",(0,t.jsx)(n.code,{children:"prefill"})," sections do not duplicate those defined in the global ",(0,t.jsx)(n.code,{children:"extraArgs"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["Additionally, in the ",(0,t.jsx)(n.strong,{children:"Heimdall"})," scheduler, you must define separate scheduling profiles for prefill and decode as shown below."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:"heimdall-values.yaml",children:"...\nconfig:\n  ...\n  plugins:\n    - type: pd-profile-handler\n    - type: prefill-filter\n    - type: decode-filter\n    ...\n  schedulingProfiles:\n    - name: prefill\n      plugins:\n        - pluginRef: prefill-filter\n        - pluginRef: queue-scorer\n        - pluginRef: max-score-picker\n    - name: decode\n      plugins:\n        - pluginRef: decode-filter\n        - pluginRef: queue-scorer\n        - pluginRef: max-score-picker\n...\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"example-pd-disaggregation-on-llama-33-70b",children:"Example: PD disaggregation on Llama 3.3 70B"}),"\n",(0,t.jsx)(n.h3,{id:"benchmarking-environment-and-configuration",children:"Benchmarking environment and configuration"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Item"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Servers"}),(0,t.jsx)(n.td,{children:"4x servers, each equipped with 4x AMD MI250 GPUs"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Networking"}),(0,t.jsx)(n.td,{children:"InfiniBand HDR"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Inference Engine"}),(0,t.jsx)(n.td,{children:"vLLM (0.10.1rc2.dev59+g0167efe20)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Model"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"meta-llama/Llama-3.3-70B-Instruct"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"PD disaggregation"}),(0,t.jsx)(n.td,{children:"6x prefill, 2x decode instances"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Benchmarking tool"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.a,{href:"https://github.com/sgl-project/genai-bench",children:"genai-bench"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Benchmarking scenario"}),(0,t.jsx)(n.td,{children:"Input sequence length ~ N(3000, 300), output sequence length ~ N(200, 20), concurrency = 64"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"deployment",children:"Deployment"}),"\n",(0,t.jsxs)(n.p,{children:["The following configuration files show how to set up PD disaggregation on the ",(0,t.jsx)(n.strong,{children:"Heimdall"})," scheduler and the ",(0,t.jsx)(n.strong,{children:"Odin"})," inference service. Prefill-only and decode-only vLLM instances each use two AMD MI250 GPUs. Six prefill instances and two decode instances \u2014 a total of eight instances run across four servers in this example."]}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsxs)(n.p,{children:["In the ",(0,t.jsx)(n.code,{children:"inference-service-values.yaml"})," file, the number of ",(0,t.jsx)(n.code,{children:"amd.com/gpu"})," is set to 4 because each MI250 GPU is recognized as two logical devices at the device driver level. Therefore, four logical devices correspond to two physical GPUs. This behavior is specific to the MI250 model."]})}),"\n",(0,t.jsxs)(s.A,{children:[(0,t.jsx)(l.A,{value:"heimdall",label:"Heimdall scheduler configuration",default:!0,children:(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:"heimdall-values.yaml",children:"global:\n  imagePullSecrets:\n    - name: moreh-registry\n\nconfig:\n  apiVersion: inference.networking.x-k8s.io/v1alpha1\n  kind: EndpointPickerConfig\n  plugins:\n    - type: pd-profile-handler\n    - type: prefill-filter\n    - type: decode-filter\n    - type: queue-scorer\n    - type: max-score-picker\n      parameters:\n        maxNumOfEndpoints: 2\n  schedulingProfiles:\n    - name: prefill\n      plugins:\n        - pluginRef: prefill-filter\n        - pluginRef: queue-scorer\n        - pluginRef: max-score-picker\n    - name: decode\n      plugins:\n        - pluginRef: decode-filter\n        - pluginRef: queue-scorer\n        - pluginRef: max-score-picker\n\ngateway:\n  name: mif\n  gatewayClassName: istio\n\nserviceMonitor:\n  labels:\n    release: prometheus-stack\n"})})}),(0,t.jsx)(l.A,{value:"odin",label:"Odin inference service configuration",children:(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:"inference-service-values.yaml {27}",children:"global:\n  imagePullSecrets:\n    - name: moreh-registry\n\nextraArgs:\n  - meta-llama/Llama-3.3-70B-Instruct\n  - --no-enable-log-requests\n  - --disable-uvicorn-access-log\n  - --quantization\n  - 'None'\n  - --kv-transfer-config\n  - '{\"kv_connector\":\"NixlConnector\", \"kv_role\":\"kv_both\"}'\n  - --no-enable-prefix-caching\n  - --tensor-parallel-size\n  - '4'\n  - --max-num-batched-tokens\n  - '8192'\n\nextraEnvVars:\n  - name: VLLM_NIXL_SIDE_CHANNEL_HOST\n    valueFrom:\n      fieldRef:\n        fieldPath: status.podIP\n  - name: UCX_TLS\n    value: rocm_copy,rocm_ipc,self,sm,rc_x\n  - name: HF_TOKEN\n    value: '<huggingFaceToken>'\n\n_common: &common\n  image:\n    repository: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/quickstart/moreh-vllm\n    tag: '20250915.1'\n\n  resources:\n    requests:\n      amd.com/gpu: '4'\n      mellanox/hca: '1'\n    limits:\n      amd.com/gpu: '4'\n      mellanox/hca: '1'\n\n  podMonitor:\n    labels:\n      release: prometheus-stack\n\ndecode:\n  replicas: 2\n\n  <<: *common\n\nprefill:\n  replicas: 6\n\n  <<: *common\n"})})})]}),"\n",(0,t.jsx)(n.p,{children:"Run the following command to deploy the services."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"helm upgrade -i heimdall moreh/heimdall \\\n    --version v0.5.0 \\\n    -n mif \\\n    -f heimdall-values.yaml\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"helm upgrade -i inference-service moreh/inference-service \\\n    --version v0.3.1 \\\n    -n mif \\\n    -f inference-service-values.yaml\n"})}),"\n",(0,t.jsx)(n.h3,{id:"benchmarking",children:"Benchmarking"}),"\n",(0,t.jsxs)(n.p,{children:["Use the ",(0,t.jsx)(n.strong,{children:"genai-bench"})," tool as follows to measure performance for the benchmarking scenario described above. Note that the ",(0,t.jsx)(n.code,{children:"--api-base"})," option must be set to your actual endpoint URL."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:'genai-bench benchmark \\\n  --api-backend vLLM \\\n  --api-key anything \\\n  --api-base http://mif-istio.mif.svc.cluster.local \\\n  --api-model-name meta-llama/Llama-3.3-70B-Instruct \\\n  --model-tokenizer meta-llama/Llama-3.3-70B-Instruct \\\n  --task text-to-text \\\n  --max-time-per-run 1000 \\\n  --max-requests-per-run 3200 \\\n  --server-engine vLLM \\\n  --traffic-scenario "N(3000,300)/(200,20)" \\\n  --num-concurrency 64 \\\n  --warmup-ratio 0.05 \\\n  --cooldown-ratio 0.05\n'})}),"\n",(0,t.jsx)(n.h3,{id:"experimental-results",children:"Experimental results"}),"\n",(0,t.jsx)(n.p,{children:"We compared the performance of our PD disaggregation setup with that of a baseline configuration using a Kubernetes Service, where requests were simply distributed in a round-robin manner across eight vLLM instances without disaggregation. Time per output token (TPOT) was reduced by approximately 30% (133 \u2192 96 ms), and as a result, the total benchmark runtime decreased by about 20% (1428.6 \u2192 1165.8 s), even though time to first token (TTFT) was sacrificed."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"End-to-end latency:"})}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Router"}),(0,t.jsx)(n.th,{children:"PD disaggregation"}),(0,t.jsx)(n.th,{children:"Total duration (s)"}),(0,t.jsx)(n.th,{children:"Mean"}),(0,t.jsx)(n.th,{children:"P50"}),(0,t.jsx)(n.th,{children:"P90"}),(0,t.jsx)(n.th,{children:"P95"}),(0,t.jsx)(n.th,{children:"P99"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Heimdall"}),(0,t.jsx)(n.td,{children:"Applied"}),(0,t.jsx)(n.td,{children:"1165.8"}),(0,t.jsx)(n.td,{children:"22.826"}),(0,t.jsx)(n.td,{children:"22.620"}),(0,t.jsx)(n.td,{children:"26.734"}),(0,t.jsx)(n.td,{children:"28.103"}),(0,t.jsx)(n.td,{children:"30.582"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"K8s Service"}),(0,t.jsx)(n.td,{children:"Not applied"}),(0,t.jsx)(n.td,{children:"1428.6"}),(0,t.jsx)(n.td,{children:"28.107"}),(0,t.jsx)(n.td,{children:"27.858"}),(0,t.jsx)(n.td,{children:"31.723"}),(0,t.jsx)(n.td,{children:"33.231"}),(0,t.jsx)(n.td,{children:"35.352"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"TTFT (time to first token):"})}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Router"}),(0,t.jsx)(n.th,{children:"PD disaggregation"}),(0,t.jsx)(n.th,{children:"Mean (s)"}),(0,t.jsx)(n.th,{children:"P50"}),(0,t.jsx)(n.th,{children:"P90"}),(0,t.jsx)(n.th,{children:"P95"}),(0,t.jsx)(n.th,{children:"P99"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Heimdall"}),(0,t.jsx)(n.td,{children:"Applied"}),(0,t.jsx)(n.td,{children:"3.7633"}),(0,t.jsx)(n.td,{children:"3.1132"}),(0,t.jsx)(n.td,{children:"6.9578"}),(0,t.jsx)(n.td,{children:"8.3785"}),(0,t.jsx)(n.td,{children:"10.023"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"K8s Service"}),(0,t.jsx)(n.td,{children:"Not applied"}),(0,t.jsx)(n.td,{children:"1.6022"}),(0,t.jsx)(n.td,{children:"1.5994"}),(0,t.jsx)(n.td,{children:"1.8094"}),(0,t.jsx)(n.td,{children:"1.9000"}),(0,t.jsx)(n.td,{children:"2.0133"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"TPOT (time per output token):"})}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Router"}),(0,t.jsx)(n.th,{children:"PD disaggregation"}),(0,t.jsx)(n.th,{children:"Mean (ms)"}),(0,t.jsx)(n.th,{children:"P50"}),(0,t.jsx)(n.th,{children:"P90"}),(0,t.jsx)(n.th,{children:"P95"}),(0,t.jsx)(n.th,{children:"P99"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Heimdall"}),(0,t.jsx)(n.td,{children:"Applied"}),(0,t.jsx)(n.td,{children:"96.029"}),(0,t.jsx)(n.td,{children:"96.166"}),(0,t.jsx)(n.td,{children:"101.29"}),(0,t.jsx)(n.td,{children:"103.34"}),(0,t.jsx)(n.td,{children:"105.94"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"K8s Service"}),(0,t.jsx)(n.td,{children:"Not applied"}),(0,t.jsx)(n.td,{children:"133.34"}),(0,t.jsx)(n.td,{children:"133.14"}),(0,t.jsx)(n.td,{children:"141.30"}),(0,t.jsx)(n.td,{children:"143.36"}),(0,t.jsx)(n.td,{children:"147.86"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:"However, the degradation in TTFT also implies that PD disaggregation should be applied carefully depending on the SLO. The method for automating scheduling in an SLO-driven manner is described in a separate document."})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}},7227(e,n,r){r.d(n,{A:()=>s});r(6540);var i=r(4164);const t="tabItem_Ymn6";var a=r(4848);function s(e){var n=e.children,r=e.hidden,s=e.className;return(0,a.jsx)("div",{role:"tabpanel",className:(0,i.A)(t,s),hidden:r,children:n})}},9489(e,n,r){r.d(n,{A:()=>P});var i=r(6540),t=r(4164),a=r(8630),s=r(4245),l=r(6347),o=r(6494),d=r(2814),c=r(5167),h=r(9900);function u(e){var n,r;return null!=(n=null==(r=i.Children.toArray(e).filter(function(e){return"\n"!==e}).map(function(e){if(!e||(0,i.isValidElement)(e)&&((n=e.props)&&"object"==typeof n&&"value"in n))return e;var n;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')}))?void 0:r.filter(Boolean))?n:[]}function p(e){var n=e.values,r=e.children;return(0,i.useMemo)(function(){var e=null!=n?n:function(e){return u(e).map(function(e){var n=e.props;return{value:n.value,label:n.label,attributes:n.attributes,default:n.default}})}(r);return function(e){var n=(0,c.XI)(e,function(e,n){return e.value===n.value});if(n.length>0)throw new Error('Docusaurus error: Duplicate values "'+n.map(function(e){return e.value}).join(", ")+'" found in <Tabs>. Every value needs to be unique.')}(e),e},[n,r])}function m(e){var n=e.value;return e.tabValues.some(function(e){return e.value===n})}function g(e){var n=e.queryString,r=void 0!==n&&n,t=e.groupId,a=(0,l.W6)(),s=function(e){var n=e.queryString,r=void 0!==n&&n,i=e.groupId;if("string"==typeof r)return r;if(!1===r)return null;if(!0===r&&!i)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return null!=i?i:null}({queryString:r,groupId:t});return[(0,d.aZ)(s),(0,i.useCallback)(function(e){if(s){var n=new URLSearchParams(a.location.search);n.set(s,e),a.replace(Object.assign({},a.location,{search:n.toString()}))}},[s,a])]}function f(e){var n,r,t,a,s=e.defaultValue,l=e.queryString,d=void 0!==l&&l,c=e.groupId,u=p(e),f=(0,i.useState)(function(){return function(e){var n,r=e.defaultValue,i=e.tabValues;if(0===i.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(r){if(!m({value:r,tabValues:i}))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+r+'" but none of its children has the corresponding value. Available values are: '+i.map(function(e){return e.value}).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");return r}var t=null!=(n=i.find(function(e){return e.default}))?n:i[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:s,tabValues:u})}),x=f[0],j=f[1],v=g({queryString:d,groupId:c}),b=v[0],y=v[1],k=(n=function(e){return e?"docusaurus.tab."+e:null}({groupId:c}.groupId),r=(0,h.Dv)(n),t=r[0],a=r[1],[t,(0,i.useCallback)(function(e){n&&a.set(e)},[n,a])]),w=k[0],P=k[1],T=function(){var e=null!=b?b:w;return m({value:e,tabValues:u})?e:null}();return(0,o.A)(function(){T&&j(T)},[T]),{selectedValue:x,selectValue:(0,i.useCallback)(function(e){if(!m({value:e,tabValues:u}))throw new Error("Can't select invalid tab value="+e);j(e),y(e),P(e)},[y,P,u]),tabValues:u}}var x=r(1062);const j="tabList__CuJ",v="tabItem_LNqP";var b=r(4848);function y(e){var n=e.className,r=e.block,i=e.selectedValue,a=e.selectValue,l=e.tabValues,o=[],d=(0,s.a_)().blockElementScrollPositionUntilNextRender,c=function(e){var n=e.currentTarget,r=o.indexOf(n),t=l[r].value;t!==i&&(d(n),a(t))},h=function(e){var n,r=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":var i,t=o.indexOf(e.currentTarget)+1;r=null!=(i=o[t])?i:o[0];break;case"ArrowLeft":var a,s=o.indexOf(e.currentTarget)-1;r=null!=(a=o[s])?a:o[o.length-1]}null==(n=r)||n.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.A)("tabs",{"tabs--block":r},n),children:l.map(function(e){var n=e.value,r=e.label,a=e.attributes;return(0,b.jsx)("li",Object.assign({role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:function(e){o.push(e)},onKeyDown:h,onClick:c},a,{className:(0,t.A)("tabs__item",v,null==a?void 0:a.className,{"tabs__item--active":i===n}),children:null!=r?r:n}),n)})})}function k(e){var n=e.lazy,r=e.children,a=e.selectedValue,s=(Array.isArray(r)?r:[r]).filter(Boolean);if(n){var l=s.find(function(e){return e.props.value===a});return l?(0,i.cloneElement)(l,{className:(0,t.A)("margin-top--md",l.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:s.map(function(e,n){return(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==a})})})}function w(e){var n=f(e);return(0,b.jsxs)("div",{className:(0,t.A)(a.G.tabs.container,"tabs-container",j),children:[(0,b.jsx)(y,Object.assign({},n,e)),(0,b.jsx)(k,Object.assign({},n,e))]})}function P(e){var n=(0,x.A)();return(0,b.jsx)(w,Object.assign({},e,{children:u(e.children)}),String(n))}},8453(e,n,r){r.d(n,{R:()=>s,x:()=>l});var i=r(6540);const t={},a=i.createContext(t);function s(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);