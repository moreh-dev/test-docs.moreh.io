"use strict";(self.webpackChunkmif_docs=self.webpackChunkmif_docs||[]).push([[1199],{823(e,n,r){r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>p,frontMatter:()=>c,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"benchmarking/more_benchmarking_for_deepseek_r1_671b_on_amd_mi300x_gpus/performance_with_prefix_cache_and_load_aware_routing","title":"Performance with prefix cache- and load-aware routing","description":"This article demonstrates how applying prefix cache-aware routing and load-aware routing when running the DeepSeek R1 671B model on an AMD MI300X GPU cluster can reduce both prefill computation and overall infrastructure cost.","source":"@site/versioned_docs/version-v0.0.0/benchmarking/more_benchmarking_for_deepseek_r1_671b_on_amd_mi300x_gpus/performance_with_prefix_cache_and_load_aware_routing.md","sourceDirName":"benchmarking/more_benchmarking_for_deepseek_r1_671b_on_amd_mi300x_gpus","slug":"/benchmarking/more_benchmarking_for_deepseek_r1_671b_on_amd_mi300x_gpus/performance_with_prefix_cache_and_load_aware_routing","permalink":"/benchmarking/more_benchmarking_for_deepseek_r1_671b_on_amd_mi300x_gpus/performance_with_prefix_cache_and_load_aware_routing","draft":false,"unlisted":false,"tags":[],"version":"v0.0.0","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Performance with prefix cache- and load-aware routing"},"sidebar":"docs","previous":{"title":"DeepSeek R1 671B on AMD MI300X GPUs: Maximum throughput","permalink":"/benchmarking/deepseek_r1_671b_on_amd_mi300x_gpus_maximum_throughput"},"next":{"title":"Features","permalink":"/features"}}');var i=r(4848),a=r(8453),s=r(9489),l=r(7227);const c={sidebar_position:1,title:"Performance with prefix cache- and load-aware routing"},o="Performance with prefix cache- and load-aware routing",d={},h=[{value:"Overview",id:"overview",level:2},{value:"Target environment and configuration",id:"target-environment-and-configuration",level:2},{value:"Deployment",id:"deployment",level:2},{value:"Prefix cache-aware routing (1p1d) configuration",id:"prefix-cache-aware-routing-1p1d-configuration",level:3},{value:"Random routing (4p1d) configuration",id:"random-routing-4p1d-configuration",level:3},{value:"Benchmarking method",id:"benchmarking-method",level:2},{value:"Experimental results",id:"experimental-results",level:2}];function u(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"performance-with-prefix-cache--and-load-aware-routing",children:"Performance with prefix cache- and load-aware routing"})}),"\n",(0,i.jsxs)(n.p,{children:["This article demonstrates how applying ",(0,i.jsx)(n.a,{href:"/features/prefix_cache_aware_routing",children:"prefix cache-aware routing"})," and ",(0,i.jsx)(n.a,{href:"/features/load_aware_routing",children:"load-aware routing"})," when running the ",(0,i.jsx)(n.strong,{children:"DeepSeek R1 671B"})," model on an AMD MI300X GPU cluster can reduce both prefill computation and overall infrastructure cost."]}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Prefix cache-aware routing reduces the amount of prefill computation in a distributed inference environment by routing requests that share the same prompt to the vLLM container where the corresponding KV cache is already stored, thereby increasing the prefix cache hit ratio."}),"\n",(0,i.jsx)(n.p,{children:"At the same time, prefix cache-aware routing can lead to request concentration on specific nodes holding KV caches for frequently used prefixes. Thus, it must be combined with a load-aware routing mechanism."}),"\n",(0,i.jsx)(n.p,{children:"The purpose of this benchmarking is to demonstrate that, when performing distributed inference of the DeepSeek R1 671B model on an AMD MI300X GPU cluster, proper routing with awareness of both prefix cache and load can achieve the same or better throughput (tokens/sec) with fewer prefill instances compared to a setup using random routing. Specifically, we compare a configuration with prefix cache-aware routing (1 prefill node and 1 decode node) against a baseline with random routing (4 prefill nodes and 1 decode node), showing that prefix cache-aware routing achieves better performance with 75% fewer prefill instances."}),"\n",(0,i.jsx)(n.p,{children:"In addition, this benchmarking validates that prefix cache-aware routing can be combined with other techniques (such as PD disaggregation) to efficiently serve large-scale MoE models in real-world deployments."}),"\n",(0,i.jsxs)(n.p,{children:["When expert parallelism is enabled, a single AMD MI300X GPU server can process tens of thousands of tokens/sec for the DeepSeek R1 671B model. Efficiently supporting the required pre- and post-processing necessitates the use of ",(0,i.jsx)(n.a,{href:"https://docs.vllm.ai/en/latest/serving/data_parallel_deployment/#external-load-balancing",children:"external data parallelism"}),", which was also applied in our ",(0,i.jsx)(n.a,{href:"/benchmarking/deepseek_r1_671b_on_amd_mi300x_gpus_maximum_throughput",children:"maximum throughput benchmarking"}),". Under this configuration, although the eight GPUs in each node cooperatively execute the model, the prefix cache is managed independently per DP rank (i.e., eight separate caches), making effective prefix cache-aware routing even more important."]}),"\n",(0,i.jsxs)(n.p,{children:["The experimental design follows the SGLang team's evaluation methodology for cache-aware load balancing. Their experiments used a ",(0,i.jsx)(n.a,{href:"https://github.com/sgl-project/sglang/pull/1990",children:"workload"})," consisting of multiple long prefix groups, and each group is perfectly balanced. Specifically, they made ",(0,i.jsx)(n.em,{children:"N"})," distinct prefixes, generated ",(0,i.jsx)(n.em,{children:"M"})," requests for each prefix, and then sent all ",(0,i.jsx)(n.em,{children:"N"})," \xd7 ",(0,i.jsx)(n.em,{children:"M"})," requests to the server to measure performance. We follow the same evaluation approach, with the key difference that our experiments are conducted in a setting where techniques such as PD disaggregation, multi-process data parallelism, and expert parallelism were applied to serve the DeepSeek R1 671B model at a high throughput."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Reference: ",(0,i.jsx)(n.a,{href:"https://lmsys.org/blog/2024-12-04-sglang-v0-4/#cache-aware-load-balancer",children:"SGLang v0.4: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer, Faster Structured Outputs"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"target-environment-and-configuration",children:"Target environment and configuration"}),"\n",(0,i.jsxs)(n.p,{children:["The experimental setup unrelated to routing schemes follows the ",(0,i.jsx)(n.a,{href:"/benchmarking/deepseek_r1_671b_on_amd_mi300x_gpus_maximum_throughput",children:"previous benchmarking"})," that measures the maximum throughput of the DeepSeek R1 671B model."]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Item"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"GPU servers"}),(0,i.jsx)(n.td,{children:"5x servers, each equipped with 8x AMD MI300X GPUs"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Networking"}),(0,i.jsx)(n.td,{children:"InfiniBand HDR"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Inference engine"}),(0,i.jsx)(n.td,{children:"Moreh vLLM (0.11.0rc2.moreh20251212)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Model"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"deepseek-ai/DeepSeek-R1"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Parallelization"}),(0,i.jsx)(n.td,{children:"EP=8 + DP=8 (external DP)"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"The specifications of each GPU server are as follows:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"CPU: 2x AMD EPYC 9474F 48-core 3.6 GHz"}),"\n",(0,i.jsx)(n.li,{children:"Main memory: 2,304 GB"}),"\n",(0,i.jsx)(n.li,{children:"GPU: 8x AMD Instinct MI300X OAM GPU 192 GB"}),"\n",(0,i.jsx)(n.li,{children:"Server: Gigabyte G593-ZX1-AAX1"}),"\n",(0,i.jsx)(n.li,{children:"Operating system: Ubuntu 22.04.4 LTS"}),"\n",(0,i.jsx)(n.li,{children:"ROCm version: 6.4.1"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"We compare the following two PD disaggregation configurations."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Random routing"})," (baseline): 4x prefill instances and 1x decode instance (4p1d)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Prefix cache-aware routing"}),": 1x prefill instance and 1x decode instance (1p1d)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In the first configuration, achieving maximum throughput for one decode instance requires four prefill instances. In the second configuration, prefix cache-aware routing reduces the prefill workload, enabling a single prefill instance to sufficiently feed the decode instance. As discussed earlier, with external DP enabled, each instance effectively has eight independent prefix caches (per DP rank). Therefore, even in the second configuration, prefix cache-aware routing remains effective, serving to route each request to the appropriate DP rank."}),"\n",(0,i.jsxs)(n.p,{children:["The first configuration simply uses Heimdall's ",(0,i.jsx)(n.code,{children:"random-picker"})," plugin. The second configuration enables the following scorers in Heimdall."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"precise-prefix-cache-scorer"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"kv-cache-utilization-scorer"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"queue-scorer"})}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"deployment",children:"Deployment"}),"\n",(0,i.jsxs)(n.p,{children:["Please make sure to install all ",(0,i.jsx)(n.a,{href:"/getting_started/prerequisites",children:"prerequisites"}),", including the following versions of the components, before starting this benchmarking. Also, please refer to the ",(0,i.jsx)(n.a,{href:"/getting_started/quickstart",children:"quickstart"})," to understand how to run the MoAI Inference Framework."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"moai-inference-framework"})," v0.1.0"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"moai-inference-preset"})," v0.1.0"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["First, you need to have a namespace for deploying and running the components of the MoAI Inference Framework. In this guide, we assume the namespace is named ",(0,i.jsx)(n.code,{children:"prefix-benchmark"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"kubectl create namespace prefix-benchmark\nkubectl label namespace prefix-benchmark mif=enabled\n"})}),"\n",(0,i.jsx)(n.h3,{id:"prefix-cache-aware-routing-1p1d-configuration",children:"Prefix cache-aware routing (1p1d) configuration"}),"\n",(0,i.jsxs)(n.p,{children:["You can use the following configuration files for the components. Click to view their contents. ",(0,i.jsxs)(n.strong,{children:["You must replace ",(0,i.jsx)(n.code,{children:"<huggingFaceToken>"})," on line 84 of ",(0,i.jsx)(n.code,{children:"heimdall-values.yaml"})," and line 23 and 58 of ",(0,i.jsx)(n.code,{children:"deepseek-r1-mi300x-prefix-cache-pd-dp.yaml"})," with your own Hugging Face token for downloading the model parameters of DeepSeek R1."]})]}),"\n",(0,i.jsxs)(s.A,{children:[(0,i.jsx)(l.A,{value:"istio",label:"Istio gateway configuration (gateway.yaml)",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",metastring:"gateway.yaml",children:"apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mif-gateway-infrastructure\n  namespace: prefix-benchmark\ndata:\n  service: |\n    spec:\n      type: ClusterIP\n      ports:\n        - name: http\n          port: 80\n          targetPort: http\n\n  deployment: |\n    spec:\n      template:\n        spec:\n          containers:\n            - name: istio-proxy\n              resources:\n                limits: null\n              ports:\n                - name: http\n                  containerPort: 80\n\n---\napiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\n  name: mif\n  namespace: prefix-benchmark\nspec:\n  gatewayClassName: istio\n  infrastructure:\n    parametersRef:\n      group: ''\n      kind: ConfigMap\n      name: mif-gateway-infrastructure\n  listeners:\n    - name: http\n      protocol: HTTP\n      port: 80\n      allowedRoutes:\n        namespaces:\n          from: All\n"})})}),(0,i.jsx)(l.A,{value:"heimdall",label:"Heimdall scheduler configuration (heimdall-values.yaml)",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",metastring:"heimdall-values.yaml {84}",children:"global:\n  imagePullSecrets:\n    - name: moreh-registry\n\ninferencePool:\n  targetPorts:\n    - number: 8000\n    - number: 8001\n    - number: 8002\n    - number: 8003\n    - number: 8004\n    - number: 8005\n    - number: 8006\n    - number: 8007\n\nconfig:\n  apiVersion: inference.networking.x-k8s.io/v1alpha1\n  kind: EndpointPickerConfig\n  plugins:\n    - type: pd-profile-handler\n    - type: queue-scorer\n    - type: kv-cache-utilization-scorer\n    - type: max-score-picker\n    - type: prefill-filter\n    - type: decode-filter\n    - type: precise-prefix-cache-scorer\n      parameters:\n        indexerConfig:\n          prefixStoreConfig:\n            cacheSize: 1000000\n            blockSize: 256\n          tokenProcessorConfig:\n            blockSize: 32\n            hashSeed: '12345'\n          kvBlockIndexConfig:\n            inMemoryConfig:\n              size: 100000000\n              podCacheSize: 10\n            enableMetrics: true\n          tokenizersPoolConfig:\n            workersCount: 8\n            minPrefixOverlapRatio: 0.8\n        kvEventsConfig:\n          zmqEndpoint: 'tcp://*:5557'\n          topicFilter: 'kv@'\n          concurrency: 32\n  schedulingProfiles:\n    - name: prefill\n      plugins:\n        - pluginRef: prefill-filter\n        - pluginRef: kv-cache-utilization-scorer\n          weight: 2\n        - pluginRef: queue-scorer\n          weight: 2\n        - pluginRef: precise-prefix-cache-scorer\n          weight: 3\n        - pluginRef: max-score-picker\n    - name: decode\n      plugins:\n        - pluginRef: decode-filter\n        - pluginRef: kv-cache-utilization-scorer\n          weight: 2\n        - pluginRef: queue-scorer\n          weight: 2\n        - pluginRef: precise-prefix-cache-scorer\n          weight: 3\n        - pluginRef: max-score-picker\n\ngateway:\n  name: mif\n  gatewayClassName: istio\n\nimage:\n  repository: '255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/heimdall'\n  tag: '954ba66'\n  pullPolicy: IfNotPresent\n\nserviceMonitor:\n  labels:\n    release: prometheus-stack\n\nextraEnvVars:\n  - name: HF_TOKEN\n    value: <huggingFaceToken>\n"})})}),(0,i.jsx)(l.A,{value:"odin",label:"Odin inference service configuration (deepseek-r1-mi300x-prefix-cache-pd-dp.yaml)",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",metastring:"deepseek-r1-mi300x-prefix-cache-pd-dp.yaml {23,58}",children:"apiVersion: odin.moreh.io/v1alpha1\nkind: InferenceService\nmetadata:\n  name: deepseek-r1-mi300x-prefill-prefix-cache\n  namespace: prefix-benchmark\nspec:\n  replicas: 1\n  inferencePoolRefs:\n    - name: heimdall\n  templateRefs:\n    - name: vllm-dp-base\n    - name: vllm-dp-prefill-meta\n    - name: vllm-deepseek-r1-prefill-mi300x-dp8ep\n  parallelism:\n    data: 8\n    expert: true\n  workerTemplate:\n    spec:\n      containers:\n        - name: main\n          image: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/quickstart/moreh-vllm:vllm_0.11.0rc1_251230\n          env:\n            - name: HF_TOKEN\n              value: <huggingFaceToken>\n            - name: ISVC_USE_KV_EVENTS\n              value: 'true'\n          resources:\n            limits:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n            requests:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n\n---\napiVersion: odin.moreh.io/v1alpha1\nkind: InferenceService\nmetadata:\n  name: deepseek-r1-mi300x-decode-prefix-cache\n  namespace: prefix-benchmark\nspec:\n  replicas: 1\n  inferencePoolRefs:\n    - name: heimdall\n  templateRefs:\n    - name: vllm-dp-base\n    - name: vllm-dp-decode-meta\n    - name: vllm-dp-decode-proxy\n    - name: vllm-deepseek-r1-decode-mi300x-dp8ep\n  parallelism:\n    data: 8\n    expert: true\n  workerTemplate:\n    spec:\n      containers:\n        - name: main\n          image: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/quickstart/moreh-vllm:vllm_0.11.0rc1_251230\n          env:\n            - name: HF_TOKEN\n              value: <huggingFaceToken>\n            - name: ISVC_USE_KV_EVENTS\n              value: 'true'\n          resources:\n            limits:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n            requests:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n"})})})]}),"\n",(0,i.jsx)(n.p,{children:"Run the following commands to deploy and run the components."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Istio gateway:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"kubectl apply -f gateway.yaml\nkubectl get pod -n prefix-benchmark -l gateway.networking.k8s.io/gateway-name=mif\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",metastring:"Expected output",children:"NAME                         READY   STATUS    RESTARTS   AGE\nmif-istio-584474ddd9-rt9p9   1/1     Running   0          163m\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Heimdall scheduler:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"helm upgrade -i heimdall moreh/heimdall \\\n    --version v0.6.0 \\\n    -n prefix-benchmark \\\n    -f heimdall-values.yaml\nkubectl get all -n prefix-benchmark -l app.kubernetes.io/instance=heimdall\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",metastring:"Expected output",children:"NAME                            READY   STATUS    RESTARTS   AGE\npod/heimdall-5576d4f48b-bgn4c   1/1     Running   0          3d1h\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Odin inference service:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"kubectl apply -f deepseek-r1-mi300x-prefix-cache-pd-dp.yaml\nkubectl get pods -n prefix-benchmark -l heimdall.moreh.io/pool=heimdall\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",metastring:"Expected output",children:"NAME                                   READY   STATUS    RESTARTS   AGE\npod/deepseek-r1-mi300x-decode-dp-0     2/2     Running   0          48m\npod/deepseek-r1-mi300x-prefill-dp-0    1/1     Running   0          65m\n"})}),"\n",(0,i.jsx)(n.h3,{id:"random-routing-4p1d-configuration",children:"Random routing (4p1d) configuration"}),"\n",(0,i.jsxs)(n.p,{children:["For the baseline random routing configuration, the Heimdall and Odin must be configured differently. Specifically, Heimdall should be set to use the ",(0,i.jsx)(n.code,{children:"random-picker"})," plugin instead of various prefix cache- and load-aware scorers, while the number of prefill replicas should be adjusted in Odin. You can use the following configuration files. Click to view their contents. ",(0,i.jsxs)(n.strong,{children:["You must replace ",(0,i.jsx)(n.code,{children:"<huggingFaceToken>"})," on line 23 and 58 of ",(0,i.jsx)(n.code,{children:"deepseek-r1-mi300x-random-pd-dp.yaml"})," with your own Hugging Face token."]})]}),"\n",(0,i.jsxs)(s.A,{children:[(0,i.jsx)(l.A,{value:"heimdall-random",label:"Heimdall scheduler configuration (heimdall-values-random.yaml)",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",metastring:"heimdall-values-random.yaml",children:"global:\n  imagePullSecrets:\n    - name: moreh-registry\n\ninferencePool:\n  targetPorts:\n    - number: 8000\n    - number: 8001\n    - number: 8002\n    - number: 8003\n    - number: 8004\n    - number: 8005\n    - number: 8006\n    - number: 8007\n\nconfig:\n  apiVersion: inference.networking.x-k8s.io/v1alpha1\n  kind: EndpointPickerConfig\n  plugins:\n    - type: pd-profile-handler\n    - type: random-picker\n    - type: prefill-filter\n    - type: decode-filter\n  schedulingProfiles:\n    - name: prefill\n      plugins:\n        - pluginRef: prefill-filter\n        - pluginRef: random-picker\n    - name: decode\n      plugins:\n        - pluginRef: decode-filter\n        - pluginRef: random-picker\n\ngateway:\n  name: mif\n  gatewayClassName: istio\n\nimage:\n  repository: '255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/heimdall'\n  tag: '954ba66'\n  pullPolicy: IfNotPresent\n\nserviceMonitor:\n  labels:\n    release: prometheus-stack\n"})})}),(0,i.jsx)(l.A,{value:"odin-random",label:"Odin inference service configuration (deepseek-r1-mi300x-random-pd-dp.yaml)",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",metastring:"deepseek-r1-mi300x-random-pd-dp.yaml {23,58}",children:"apiVersion: odin.moreh.io/v1alpha1\nkind: InferenceService\nmetadata:\n  name: deepseek-r1-mi300x-prefill-random\n  namespace: prefix-benchmark\nspec:\n  replicas: 4\n  inferencePoolRefs:\n    - name: heimdall\n  templateRefs:\n    - name: vllm-dp-base\n    - name: vllm-dp-prefill-meta\n    - name: vllm-deepseek-r1-prefill-mi300x-dp8ep\n  parallelism:\n    data: 8\n    expert: true\n  workerTemplate:\n    spec:\n      containers:\n        - name: main\n          image: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/quickstart/moreh-vllm:vllm_0.11.0rc1_251230\n          env:\n            - name: HF_TOKEN\n              value: <huggingFaceToken>\n            - name: ISVC_USE_KV_EVENTS\n              value: 'false'\n          resources:\n            limits:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n            requests:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n\n---\napiVersion: odin.moreh.io/v1alpha1\nkind: InferenceService\nmetadata:\n  name: deepseek-r1-mi300x-decode-random\n  namespace: prefix-benchmark\nspec:\n  replicas: 1\n  inferencePoolRefs:\n    - name: heimdall\n  templateRefs:\n    - name: vllm-dp-base\n    - name: vllm-dp-decode-meta\n    - name: vllm-dp-decode-proxy\n    - name: vllm-deepseek-r1-decode-mi300x-dp8ep\n  parallelism:\n    data: 8\n    expert: true\n  workerTemplate:\n    spec:\n      containers:\n        - name: main\n          image: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/quickstart/moreh-vllm:vllm_0.11.0rc1_251230\n          env:\n            - name: HF_TOKEN\n              value: <huggingFaceToken>\n            - name: ISVC_USE_KV_EVENTS\n              value: 'false'\n          resources:\n            limits:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n            requests:\n              amd.com/gpu: '8'\n              mellanox/hca: '1'\n"})})})]}),"\n",(0,i.jsx)(n.p,{children:"Run the following commands to deploy and run the components for the baseline configuration."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"helm upgrade -i heimdall moreh/heimdall \\\n    --version v0.6.0 \\\n    -n prefix-benchmark \\\n    -f heimdall-values-random.yaml\nkubectl apply -f deepseek-r1-mi300x-random-pd-dp.yaml\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"benchmarking-method",children:"Benchmarking method"}),"\n",(0,i.jsxs)(n.p,{children:["Following the same experimental methodology as the SGLang team, we construct a scenario in which multiple requests share prefixes by generating ",(0,i.jsx)(n.strong,{children:"200"})," distinct system prompts and creating ",(0,i.jsx)(n.strong,{children:"15"})," requests per system prompt, resulting in a total of ",(0,i.jsx)(n.strong,{children:"3,000"})," requests sent to the server (API endpoint). Each request consists of a 4,000-token system prompt (a shared prefix) and a 200-token question, and generates a 1,000-token output."]}),"\n",(0,i.jsxs)(n.p,{children:["We use the ",(0,i.jsx)(n.a,{href:"https://github.com/kubernetes-sigs/inference-perf",children:"inference-perf"})," tool, which provides the ability to generate requests with shared prefixes and measure various performance metrics."]}),"\n",(0,i.jsx)(n.p,{children:"Because the effectiveness of routing policies can vary with the request rate, we apply load at different request rates across four stages and measure performance."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Stage 0: 20 requests/sec for 150 seconds (a warm-up stage in which all 3,000 requests are sent once to populate the prefix cache)"}),"\n",(0,i.jsx)(n.li,{children:"Stage 1: 10 requests/sec for 80 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Stage 2: 50 requests/sec for 80 seconds"}),"\n",(0,i.jsx)(n.li,{children:"Stage 3: 80 requests/sec for 80 seconds"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["To run the benchmark, create the following resources. ",(0,i.jsxs)(n.strong,{children:["You must also replace ",(0,i.jsx)(n.code,{children:"<huggingFaceToken>"})," on line 8 of ",(0,i.jsx)(n.code,{children:"inference-perf-benchmark.yaml"})," with your own Hugging Face token."]})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",metastring:"inference-perf-benchmark.yaml {8}",children:"apiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-secret\n  namespace: prefix-benchmark\ntype: Opaque\nstringData:\n  hf_api_token: <huggingFaceToken>\n\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: inference-perf-shared-prefix-config\n  namespace: prefix-benchmark\ndata:\n  config.yml: |\n    load:\n      type: poisson\n      interval: 0\n      stages:\n      - rate: 20.0\n        duration: 150\n      - rate: 10.0\n        duration: 80\n      - rate: 50.0\n        duration: 80\n      - rate: 80.0\n        duration: 80\n      num_workers: 4\n      worker_max_concurrency: 500\n      worker_max_tcp_connections: 2500\n      request_timeout: 1200.0\n    api:\n      type: completion\n      streaming: true\n    server:\n      type: vllm\n      model_name: deepseek-ai/DeepSeek-R1\n      base_url: http://mif-istio.prefix-benchmark.svc.cluster.local:80\n      ignore_eos: true\n    data:\n      type: shared_prefix\n      shared_prefix:\n        num_groups: 200\n        num_prompts_per_group: 15\n        system_prompt_len: 4000\n        question_len: 200\n        output_len: 1000\n    report:\n      request_lifecycle:\n        summary: true\n        per_stage: true\n        per_request: false\n\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: inference-perf-shared-prefix\n  namespace: prefix-benchmark\n  labels:\n    app: inference-perf\n    benchmark: shared-prefix\nspec:\n  template:\n    metadata:\n      labels:\n        app: inference-perf\n        benchmark: shared-prefix\n    spec:\n      containers:\n        - name: inference-perf\n          image: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/inference-perf:a439f819\n          imagePullPolicy: IfNotPresent\n          command: ['sh', '-c']\n          args:\n            - |\n              inference-perf --config_file /etc/config/config.yml\n              echo \"[INFO] Benchmark completed. Keeping container alive...\"\n              sleep infinity\n          env:\n            - name: HF_TOKEN\n              valueFrom:\n                secretKeyRef:\n                  name: hf-secret\n                  key: hf_api_token\n          volumeMounts:\n            - name: config-volume\n              mountPath: /etc/config\n              readOnly: true\n      restartPolicy: Never\n      volumes:\n        - name: config-volume\n          configMap:\n            name: inference-perf-shared-prefix-config\n"})}),"\n",(0,i.jsx)(n.p,{children:"Apply the resources and run the benchmark."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"kubectl apply -f inference-perf-benchmark.yaml\n"})}),"\n",(0,i.jsx)(n.p,{children:"Monitor the benchmark progress as follows."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"kubectl logs -n prefix-benchmark -f job/inference-perf-shared-prefix\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"experimental-results",children:"Experimental results"}),"\n",(0,i.jsx)(n.p,{children:"The following tables show TTFT (time to first token) percentiles (P50, P75, and P90) and throughput (output tokens/sec) for each request rate and configuration."}),"\n",(0,i.jsxs)(n.p,{children:["At a rate of ",(0,i.jsx)(n.strong,{children:"10 requests/sec"})," (Stage 1):"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Configuration"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P50 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P75 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P90 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"Output tokens/sec"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"Output tokens/sec per node"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Random (4p1d)"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"1.73"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"2.20"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"2.64"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"4,098"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"820"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Prefix cache-aware (1p1d)"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"1.43"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"5.20"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"7.25"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"4,108"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"2,054"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Speedup"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"1.21x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"0.42x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"0.36x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"1.00x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"2.50x"})})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:["At a rate of ",(0,i.jsx)(n.strong,{children:"50 requests/sec"})," (Stage 2):"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Configuration"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P50 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P75 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P90 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"Output tokens/sec"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"Output tokens/sec per node"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Random (4p1d)"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"48.79"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"204.55"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"255.93"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"4,266"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"853"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Prefix cache-aware (1p1d)"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"2.33"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"6.25"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"8.46"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"9,756"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"4,878"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Speedup"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"20.94x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"32.73x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"30.25x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"2.29x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"5.72x"})})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:["At a rate of ",(0,i.jsx)(n.strong,{children:"80 requests/sec"})," (Stage 3):"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Configuration"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P50 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P75 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"P90 TTFT (s)"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"Output tokens/sec"}),(0,i.jsx)(n.th,{style:{textAlign:"right"},children:"Output tokens/sec per node"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Random (4p1d)"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"56.81"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"258.54"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"289.51"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"4,037"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"807"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Prefix cache-aware (1p1d)"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"1.38"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"1.62"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"1.97"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"9,030"}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:"4,515"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Speedup"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"41.17x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"159.59x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"146.96x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"2.24x"})}),(0,i.jsx)(n.td,{style:{textAlign:"right"},children:(0,i.jsx)(n.strong,{children:"5.59x"})})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"The key observations are as follows."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Applying prefix cache-aware routing increases the cache hit ratio and significantly reduces TTFT, especially under higher load, even with fewer prefill nodes."}),"\n",(0,i.jsxs)(n.li,{children:["Compared to using random routing on five nodes, applying prefix cache-aware routing on two nodes achieves higher throughput, delivering ",(0,i.jsx)(n.strong,{children:"2.5-5.6x"})," improvements in cost efficiency (output tokens/sec per node)."]}),"\n",(0,i.jsx)(n.li,{children:"As a result, prefix cache- and load-aware routing delivers significant infrastructure cost savings while maintaining or improving service quality."}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},7227(e,n,r){r.d(n,{A:()=>s});r(6540);var t=r(4164);const i="tabItem_Ymn6";var a=r(4848);function s(e){var n=e.children,r=e.hidden,s=e.className;return(0,a.jsx)("div",{role:"tabpanel",className:(0,t.A)(i,s),hidden:r,children:n})}},9489(e,n,r){r.d(n,{A:()=>_});var t=r(6540),i=r(4164),a=r(8630),s=r(4245),l=r(6347),c=r(6494),o=r(2814),d=r(5167),h=r(9900);function u(e){var n,r;return null!=(n=null==(r=t.Children.toArray(e).filter(function(e){return"\n"!==e}).map(function(e){if(!e||(0,t.isValidElement)(e)&&((n=e.props)&&"object"==typeof n&&"value"in n))return e;var n;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')}))?void 0:r.filter(Boolean))?n:[]}function p(e){var n=e.values,r=e.children;return(0,t.useMemo)(function(){var e=null!=n?n:function(e){return u(e).map(function(e){var n=e.props;return{value:n.value,label:n.label,attributes:n.attributes,default:n.default}})}(r);return function(e){var n=(0,d.XI)(e,function(e,n){return e.value===n.value});if(n.length>0)throw new Error('Docusaurus error: Duplicate values "'+n.map(function(e){return e.value}).join(", ")+'" found in <Tabs>. Every value needs to be unique.')}(e),e},[n,r])}function m(e){var n=e.value;return e.tabValues.some(function(e){return e.value===n})}function g(e){var n=e.queryString,r=void 0!==n&&n,i=e.groupId,a=(0,l.W6)(),s=function(e){var n=e.queryString,r=void 0!==n&&n,t=e.groupId;if("string"==typeof r)return r;if(!1===r)return null;if(!0===r&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return null!=t?t:null}({queryString:r,groupId:i});return[(0,o.aZ)(s),(0,t.useCallback)(function(e){if(s){var n=new URLSearchParams(a.location.search);n.set(s,e),a.replace(Object.assign({},a.location,{search:n.toString()}))}},[s,a])]}function x(e){var n,r,i,a,s=e.defaultValue,l=e.queryString,o=void 0!==l&&l,d=e.groupId,u=p(e),x=(0,t.useState)(function(){return function(e){var n,r=e.defaultValue,t=e.tabValues;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(r){if(!m({value:r,tabValues:t}))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+r+'" but none of its children has the corresponding value. Available values are: '+t.map(function(e){return e.value}).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");return r}var i=null!=(n=t.find(function(e){return e.default}))?n:t[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:s,tabValues:u})}),f=x[0],j=x[1],v=g({queryString:o,groupId:d}),y=v[0],b=v[1],k=(n=function(e){return e?"docusaurus.tab."+e:null}({groupId:d}.groupId),r=(0,h.Dv)(n),i=r[0],a=r[1],[i,(0,t.useCallback)(function(e){n&&a.set(e)},[n,a])]),w=k[0],_=k[1],A=function(){var e=null!=y?y:w;return m({value:e,tabValues:u})?e:null}();return(0,c.A)(function(){A&&j(A)},[A]),{selectedValue:f,selectValue:(0,t.useCallback)(function(e){if(!m({value:e,tabValues:u}))throw new Error("Can't select invalid tab value="+e);j(e),b(e),_(e)},[b,_,u]),tabValues:u}}var f=r(1062);const j="tabList__CuJ",v="tabItem_LNqP";var y=r(4848);function b(e){var n=e.className,r=e.block,t=e.selectedValue,a=e.selectValue,l=e.tabValues,c=[],o=(0,s.a_)().blockElementScrollPositionUntilNextRender,d=function(e){var n=e.currentTarget,r=c.indexOf(n),i=l[r].value;i!==t&&(o(n),a(i))},h=function(e){var n,r=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":var t,i=c.indexOf(e.currentTarget)+1;r=null!=(t=c[i])?t:c[0];break;case"ArrowLeft":var a,s=c.indexOf(e.currentTarget)-1;r=null!=(a=c[s])?a:c[c.length-1]}null==(n=r)||n.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":r},n),children:l.map(function(e){var n=e.value,r=e.label,a=e.attributes;return(0,y.jsx)("li",Object.assign({role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:function(e){c.push(e)},onKeyDown:h,onClick:d},a,{className:(0,i.A)("tabs__item",v,null==a?void 0:a.className,{"tabs__item--active":t===n}),children:null!=r?r:n}),n)})})}function k(e){var n=e.lazy,r=e.children,a=e.selectedValue,s=(Array.isArray(r)?r:[r]).filter(Boolean);if(n){var l=s.find(function(e){return e.props.value===a});return l?(0,t.cloneElement)(l,{className:(0,i.A)("margin-top--md",l.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:s.map(function(e,n){return(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==a})})})}function w(e){var n=x(e);return(0,y.jsxs)("div",{className:(0,i.A)(a.G.tabs.container,"tabs-container",j),children:[(0,y.jsx)(b,Object.assign({},n,e)),(0,y.jsx)(k,Object.assign({},n,e))]})}function _(e){var n=(0,f.A)();return(0,y.jsx)(w,Object.assign({},e,{children:u(e.children)}),String(n))}},8453(e,n,r){r.d(n,{R:()=>s,x:()=>l});var t=r(6540);const i={},a=t.createContext(i);function s(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);