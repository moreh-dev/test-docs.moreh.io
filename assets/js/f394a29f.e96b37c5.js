"use strict";(self.webpackChunkmif_docs=self.webpackChunkmif_docs||[]).push([[177],{4846(e,n,r){r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>c,metadata:()=>s,toc:()=>t});const s=JSON.parse('{"id":"reference/odin_inference_service","title":"Odin inference service","description":"Odin is the component that launches individual inference pods at scale. These inference pods run Moreh vLLM by default, but they can also use open-source vLLM or SGLang when needed.","source":"@site/versioned_docs/version-v0.0.0/reference/odin_inference_service.md","sourceDirName":"reference","slug":"/reference/odin_inference_service","permalink":"/reference/odin_inference_service","draft":false,"unlisted":false,"tags":[],"version":"v0.0.0","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Odin inference service"},"sidebar":"docs","previous":{"title":"Heimdall scheduler","permalink":"/reference/heimdall_scheduler"}}');var o=r(4848),i=r(8453);const c={sidebar_position:2,title:"Odin inference service"},l="Odin inference service",d={},t=[{value:"Manual configuration",id:"manual-configuration",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"odin-inference-service",children:"Odin inference service"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Odin"})," is the component that launches individual inference pods at scale. These inference pods run ",(0,o.jsx)(n.a,{href:"https://moreh.io/moreh-vllm/",children:"Moreh vLLM"})," by default, but they can also use open-source vLLM or SGLang when needed."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"manual-configuration",children:"Manual configuration"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",metastring:"{19}",children:'global:\n  imagePullSecrets:\n    - name: moreh-registry\n\nextraArgs:\n  - meta-llama/Llama-3.2-1B-Instruct\n  - --quantization\n  - "None"\n  - --tensor-parallel-size\n  - "2"\n  - --max-num-batched-tokens\n  - "8192"\n  - --no-enable-prefix-caching\n  - --no-enable-log-requests\n  - --disable-uvicorn-access-log\n\nextraEnvVars:\n  - name: HF_TOKEN\n    value: <huggingFaceToken>\ndecode:\n  replicas: 2\n\n  image:\n    repository: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/quickstart/moreh-vllm\n    tag: "20250915.1"\n\n  resources:\n    requests:\n      amd.com/gpu: "2"\n      mellanox/hca: "1"\n    limits:\n      amd.com/gpu: "2"\n      mellanox/hca: "1"\n\n  extraArgs: []\n\n  podMonitor:\n    labels:\n      release: prometheus-stack\n\nprefill:\n  enabled: true\n  ...\n'})}),"\n",(0,o.jsxs)(n.p,{children:["A single Odin configuration file can specify the configurations for two types of inference pods -- ",(0,o.jsx)(n.code,{children:"decode"})," and ",(0,o.jsx)(n.code,{children:"prefill"}),". When ",(0,o.jsx)(n.code,{children:"prefill.enabled"})," is set to true, the ",(0,o.jsx)(n.code,{children:"decode"})," section defines the configuration for decode-only pods, while the ",(0,o.jsx)(n.code,{children:"prefill"})," section defines the configuration for prefill-only pods. When ",(0,o.jsx)(n.code,{children:"prefill.enabled"})," is false, only the ",(0,o.jsx)(n.code,{children:"decode"})," section is used, and it defines the configuration for pods that run the model end-to-end (not decode-only)."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"decode.replicas"}),": the number of decode-only (or end-to-end) pods."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"prefill.replicas"}),": the number of prefill-only pods."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"decode.resources"}),": specifies how much of resources each decode-only (or end-to-end) pod needs."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"prefill.resources"}),": specifies how much of resources each prefill-only pod needs."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"extraArgs"}),": the list of arguments passed to all pods."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"extraEnvVars"}),": the list of environment variables passed to all pods."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"decode.extraArgs"}),": the list of additional arguments passed only to decode-only pods; none of these may overlap with the global ",(0,o.jsx)(n.code,{children:"extraArgs"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"prefill.extraArgs"}),": the list of additional arguments passed only to prefill-only pods; none of these may overlap with the global ",(0,o.jsx)(n.code,{children:"extraArgs"}),"."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(a,{...e})}):a(e)}},8453(e,n,r){r.d(n,{R:()=>c,x:()=>l});var s=r(6540);const o={},i=s.createContext(o);function c(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:c(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);